{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMG_DIM = 364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bensYCC(bgr, weight=4, gamma=10):\n",
    "        \n",
    "    # convert to y, cr, cb so that we can modify the image based on just the y (brightness)\n",
    "    ycc = cv2.cvtColor(bgr, cv2.COLOR_BGR2YCrCb)\n",
    "    y, cr, cb = cv2.split(ycc)\n",
    "\n",
    "    # perform bens algorithm on the y component\n",
    "    y = cv2.addWeighted(y, weight, cv2.GaussianBlur(y, (0,0), gamma), -weight, 128)\n",
    "\n",
    "    # merge the ycc back together, and recolor it\n",
    "    ycc_modified = cv2.merge((y, cr, cb))\n",
    "    bens = cv2.cvtColor(ycc_modified, cv2.COLOR_YCrCb2BGR)\n",
    "    \n",
    "    return bens \n",
    "\n",
    "\n",
    "def bensGray(gray, weight=4, gamma=10):\n",
    "        \n",
    "    # perform bens algorithm on the y component\n",
    "    bens = cv2.addWeighted(gray, weight, cv2.GaussianBlur(gray, (0,0), gamma), -weight, 128)\n",
    "    \n",
    "    return bens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(gray, img, percent_smaller):\n",
    "    \n",
    "    thresh = 8\n",
    "    \n",
    "    top    = 0\n",
    "    left   = 0\n",
    "    bottom = gray.shape[0] - 1\n",
    "    right  = gray.shape[1] - 1\n",
    "    \n",
    "    # work in from the top and bottom along the middle collumn\n",
    "    middleCol = gray[:, int(gray.shape[1]/2)] > thresh\n",
    "    while middleCol[top] == 0:\n",
    "        top += 1\n",
    "    while middleCol[bottom] == 0:\n",
    "        bottom -= 1\n",
    "        \n",
    "    # work in from the sides along the middle row\n",
    "    middleRow = gray[int(gray.shape[0]/2)] > thresh\n",
    "    while middleRow[left] == 0:\n",
    "        left += 1\n",
    "    while middleRow[right] == 0:\n",
    "        right -= 1\n",
    "        \n",
    "    height = bottom - top\n",
    "    width  = right - left\n",
    "    \n",
    "    bottom -= int(percent_smaller*height)\n",
    "    top    += int(percent_smaller*height)\n",
    "    right  -= int(percent_smaller*width)\n",
    "    left   += int(percent_smaller*width)\n",
    "        \n",
    "    if height < 100 or width < 100:\n",
    "        print(\"Error: squareUp: bottom:\", bottom, \"top:\", top)\n",
    "        print(\"Error: squareUp: right:\", right, \"left:\", left)\n",
    "        return img\n",
    "    \n",
    "    return img[top:bottom, left:right]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflectAndSquareUp(img):\n",
    "    \n",
    "    height = img.shape[0]\n",
    "    width  = img.shape[1]\n",
    "    \n",
    "    # if its portrait mode, it's probably already kind of square. Make it properly square by cutting\n",
    "    # down the height until the dimensions match\n",
    "    if (height > width):\n",
    "        \n",
    "        offset = int((height - width)/2)\n",
    "        return img[offset:offset+width]\n",
    "    \n",
    "    # otherwise, do the whole reflection thingo\n",
    "    else:\n",
    "        if len(img.shape) == 3:\n",
    "            new_img = np.zeros((width, width, img.shape[2]), np.uint8)\n",
    "        else:\n",
    "            new_img = np.zeros((width, width), np.uint8)\n",
    "\n",
    "        #  0  |\n",
    "        #     |\n",
    "        #  h1 |####\n",
    "        #     |####\n",
    "        #     |####\n",
    "        #  h2 |\n",
    "        #     |\n",
    "\n",
    "        h1 = int((width - height)/2)\n",
    "        h2 = h1 + height\n",
    "\n",
    "        # paste the original into the center\n",
    "        new_img[h1:h2,:] = img\n",
    "\n",
    "        # paste in the reflections\n",
    "        for i in range(h1):\n",
    "            new_img[h1-i] = img[i]\n",
    "\n",
    "        for i in range(width - h2):\n",
    "            new_img[h2+i] = img[height - i - 1]\n",
    "\n",
    "        return new_img\n",
    "\n",
    "def circleMask(img):\n",
    "    \n",
    "    if (img.shape[0] != img.shape[1]):\n",
    "        print(\"Error: circle mask assumes square image\")\n",
    "        return img\n",
    "    \n",
    "    dim = img.shape[0]\n",
    "    half = int(dim/2)\n",
    "    \n",
    "    # crop out circle:\n",
    "    circle_mask = np.zeros((dim, dim), np.uint8)\n",
    "    circle_mask = cv2.circle(circle_mask, (half, half), half, 1, thickness=-1)\n",
    "\n",
    "    return cv2.bitwise_and(img, img, mask=circle_mask)\n",
    "\n",
    "def clahe_gray(gray, clipLimit=4.0, grid=8):\n",
    "\n",
    "    #-----Applying CLAHE to L-channel-------------------------------------------\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=(grid,grid))\n",
    "    return clahe.apply(gray)\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "                     for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test different versions of colourful eyes\n",
    "\n",
    "# # the main dataframes\n",
    "# df_2019 = pd.read_csv(f\"../aptos2019/train.csv\") \n",
    "# df_2019.id_code = df_2019.id_code.apply(lambda x: x + \".png\")\n",
    "\n",
    "# # df_2015 = pd.read_csv(f\"../aptos2015/trainLabels.csv\") \n",
    "# # df_2015.image   = df_2015.image.apply(lambda   x: x + \".jpeg\")\n",
    "\n",
    "# # Display some random images from Data Set with class categories.\n",
    "# figure=plt.figure(figsize=(22,20))\n",
    "# for target_class in range(5):\n",
    "#     for i, (idx, row ) in enumerate(df_2019.loc[df_2019.diagnosis == target_class]\n",
    "#                                     .sample(1)\n",
    "#                                     .iterrows()):\n",
    "#         # open the file\n",
    "#         imagefile = f\"../aptos2019/train_images/{row['id_code']}\" \n",
    "#         img = cv2.imread(imagefile)\n",
    "#         green = img[:,:,1]\n",
    "        \n",
    "#         # original version\n",
    "#         rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         ax = figure.add_subplot(5,4, int(target_class)*4+2*i+1)\n",
    "#         plt.imshow(rgb)\n",
    "        \n",
    "        \n",
    "#         # colour ben\n",
    "#         cropped = crop(green, img, 0.02)\n",
    "#         squared = reflectAndSquareUp(cropped)\n",
    "#         resized = cv2.resize(squared, (IMG_DIM, IMG_DIM))\n",
    "#         circled = circleMask(resized)\n",
    "#         equalised = adjust_gamma(circled, 1+np.log(100)-np.log(np.median(circled)))\n",
    "        \n",
    "#         ax = figure.add_subplot(5,4, int(target_class)*4+2*i+2)\n",
    "#         plt.imshow(cv2.cvtColor(bensYCC(equalised), cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "#         # ------------ greys --------------\n",
    "#         cropped = crop(green, green, 0.02)\n",
    "#         squared = reflectAndSquareUp(cropped)\n",
    "#         resized = cv2.resize(squared, (IMG_DIM, IMG_DIM))\n",
    "#         circled = circleMask(resized)\n",
    "#         equalised = adjust_gamma(circled, 1+np.log(100)-np.log(np.median(circled)))\n",
    "        \n",
    "#         # green ben\n",
    "#         ax = figure.add_subplot(5,4, int(target_class)*4+2*i+3)\n",
    "#         plt.imshow(bensGray(equalised), cmap='gray')\n",
    "        \n",
    "# #         green clahe\n",
    "#         ax = figure.add_subplot(5,4, int(target_class)*4+2*i+4)\n",
    "#         plt.imshow(clahe_gray(equalised), cmap='gray')\n",
    "        \n",
    "imagefile = f\"../aptos2015/train_images/1986_left.jpeg\" \n",
    "img = cv2.imread(imagefile)\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "Error: 492_right.jpeg failed\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "Error: 1986_left.jpeg failed\n",
      "1600\n",
      "1700\n",
      "Error: 2157_left.jpeg failed\n",
      "Error: 2236_right.jpeg failed\n",
      "1800\n",
      "Error: 2248_left.jpeg failed\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:50: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "Error: squareUp: bottom: 1943 top: 1924\n",
      "Error: squareUp: right: 2337 left: 2319\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n"
     ]
    }
   ],
   "source": [
    "def process_images(year, test=True):\n",
    "    \n",
    "    # set the year\n",
    "    if year == \"2019\":\n",
    "        directory = \"../aptos2019/train_images/\" \n",
    "        file_end  = \".png\"\n",
    "        df        = pd.read_csv(f\"../aptos2019/train.csv\") \n",
    "    elif year == \"2015\":\n",
    "        directory = \"../aptos2015/train_images/\" \n",
    "        file_end  = \".jpeg\"\n",
    "        df        = pd.read_csv(f\"../aptos2015/trainLabels.csv\") \n",
    "        df[\"id_code\"] = df.image\n",
    "        \n",
    "    df.id_code = df.id_code.apply(lambda x: x + file_end)\n",
    "    \n",
    "    # go through all zeh images und changen them\n",
    "    if test:\n",
    "        figure=plt.figure(figsize=(22,20))\n",
    "    for count, file_name in enumerate(df.id_code.values):\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            print(count)\n",
    "        \n",
    "        bens_colour_file = directory + \"ben_colour_\" + file_name\n",
    "        bens_green_file = directory + \"ben_green_\" + file_name\n",
    "        clahe_green_file = directory + \"clahe_green_\" + file_name\n",
    "        \n",
    "        if os.path.isfile(bens_colour_file) and \\\n",
    "            os.path.isfile(bens_green_file) and \\\n",
    "            os.path.isfile(clahe_green_file):\n",
    "                continue\n",
    "                \n",
    "        # ---- do preprocessing common to all ----\n",
    "        try:\n",
    "            bgr = cv2.imread(directory + file_name)\n",
    "            if test:\n",
    "                rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "                ax = figure.add_subplot(5,4, 4*count+1)\n",
    "                plt.imshow(rgb)\n",
    "\n",
    "            green   = bgr[:,:,1] # use green as a greyscale\n",
    "            cropped = crop(green, bgr, 0.02)\n",
    "            squared = reflectAndSquareUp(cropped)\n",
    "\n",
    "            resized_bgr = cv2.resize(squared, (IMG_DIM, IMG_DIM))\n",
    "            circled_bgr = circleMask(resized_bgr)\n",
    "            equalised_bgr = adjust_gamma(circled_bgr, 1+np.log(100)-np.log(np.median(circled_bgr)))\n",
    "\n",
    "            squared_green = squared[:,:,1]\n",
    "            resized_green = cv2.resize(squared_green, (IMG_DIM, IMG_DIM))\n",
    "            circled_green = circleMask(resized_green)\n",
    "            equalised_green = adjust_gamma(circled_green, 1+np.log(100)-np.log(np.median(circled_green)))\n",
    "\n",
    "            # ----- Bens Coloured -----\n",
    "            if not os.path.isfile(bens_colour_file):\n",
    "                new_img = bensYCC(equalised_bgr)\n",
    "                if test:\n",
    "                    rgb = cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB)\n",
    "                    ax = figure.add_subplot(5,4, 4*count+2)\n",
    "                    plt.imshow(rgb)\n",
    "                else:\n",
    "                    cv2.imwrite(bens_colour_file, new_img)\n",
    "\n",
    "            # ----- Bens Green -----\n",
    "            if not os.path.isfile(bens_green_file):\n",
    "                new_img = bensGray(equalised_green)\n",
    "                if test:\n",
    "                    ax = figure.add_subplot(5,4, 4*count+3)\n",
    "                    plt.imshow(new_img, cmap='gray')\n",
    "                else:\n",
    "                    cv2.imwrite(bens_green_file, new_img)\n",
    "\n",
    "            # ----- Clahe Green -----\n",
    "            if not os.path.isfile(clahe_green_file):\n",
    "                new_img = clahe_gray(equalised_green)\n",
    "                if test:\n",
    "                    ax = figure.add_subplot(5,4, 4*count+4)\n",
    "                    plt.imshow(new_img, cmap='gray')\n",
    "                else:\n",
    "                    cv2.imwrite(clahe_green_file, new_img)\n",
    "        except:\n",
    "            print(f\"Error: {file_name} failed\")\n",
    "            \n",
    "        if test and count == 4:\n",
    "            break\n",
    "\n",
    "\n",
    "process_images(\"2015\", test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-90ea5f316120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy  as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2 \n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications import DenseNet121\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Input\n",
    "from keras.layers import Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.activations import softmax, relu\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Global constants\n",
    "IMG_DIM      = 256\n",
    "BATCH_SIZE   = 32\n",
    "CHANNEL_SIZE = 3\n",
    "NUM_CLASSES  = 5\n",
    "\n",
    "print(os.listdir(\"../\"))\n",
    "print(os.listdir(\"../input/\"))\n",
    "print(os.listdir(\"../input/aptos2019-blindness-detection\"))\n",
    "print(os.listdir(\"../input/densenetmulti\"))\n",
    "\n",
    "INPUT_FOLDER     ='../input/aptos2019-blindness-detection/'\n",
    "TEST_IMAGES_DIR  = INPUT_FOLDER + \"test_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(INPUT_FOLDER + 'test.csv')\n",
    "test_df['id_code'] = test_df['id_code'].apply(lambda x:  x + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "We need to crop and preprocess all the test images into the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_convert(y_val):\n",
    "    y_val = y_val.astype(int).sum(axis=1) - 1\n",
    "    #y_val= np.argmax(y_val, axis=1)\n",
    "    return y_val\n",
    "\n",
    "def crop(bgr):\n",
    "    \n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    thresh = 5\n",
    "    \n",
    "    # remove any black regions, where black is y under the threshold\n",
    "    rowMaxes = gray.max(axis=1)\n",
    "    top = 0\n",
    "    while rowMaxes[top] < thresh:\n",
    "        top += 1\n",
    "    bottom = len(rowMaxes) - 1\n",
    "    while rowMaxes[bottom] < thresh:\n",
    "        bottom -= 1\n",
    "        \n",
    "    middleRow = gray[int((bottom-top)/2)]\n",
    "    left = 0\n",
    "    while middleRow[left] < thresh:\n",
    "        left += 1\n",
    "    right = len(middleRow) - 1\n",
    "    while middleRow[right] < thresh:\n",
    "        right -= 1\n",
    "        \n",
    "    height = bottom - top\n",
    "    width  = right - left\n",
    "        \n",
    "    if height < 100 or width < 100:\n",
    "        print(\"Error: squareUp: bottom:\", bottom, \"top:\", top)\n",
    "        print(\"Error: squareUp: right:\", right, \"left:\", left)\n",
    "        return bgr\n",
    "    \n",
    "    return bgr[top:bottom, left:right]\n",
    "\n",
    "# assumes BGR\n",
    "def colourfulEyes(bgr, weight=4, gamma=15):\n",
    "        \n",
    "    # convert to y, cr, cb so that we can modify the image based on just the y (brightness)\n",
    "    ycc = cv2.cvtColor(bgr, cv2.COLOR_BGR2YCrCb)\n",
    "    y, cr, cb = cv2.split(ycc)\n",
    "\n",
    "    # perform bens algorithm on the y component\n",
    "    y = cv2.addWeighted(y, weight, cv2.GaussianBlur(y, (0,0), gamma), -weight, 128)\n",
    "\n",
    "    # merge the ycc back together, and recolor it\n",
    "    ycc_modified = cv2.merge((y, cr, cb))\n",
    "    modified = cv2.cvtColor(ycc_modified, cv2.COLOR_YCrCb2BGR)\n",
    "    \n",
    "    return modified \n",
    "\n",
    "def processImageBgrToRgb(bgr):\n",
    "    modified = crop(bgr) \n",
    "    modified = cv2.resize(modified, (IMG_DIM, IMG_DIM))\n",
    "    modified = colourfulEyes(modified)\n",
    "    modified = cv2.cvtColor(modified, cv2.COLOR_BGR2RGB)\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(img_dim, CHANNELS, n_class):\n",
    "    \n",
    "    input_tensor=Input(shape=(img_dim, img_dim, CHANNELS))\n",
    "    \n",
    "    base_model = DenseNet121(weights=None, include_top=False, input_tensor=input_tensor)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(512, activation=relu)(x)\n",
    "    x = Dropout(0.15)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    output_layer = Dense(n_class, activation='sigmoid', name=\"Output_Layer\")(x)\n",
    "    model = Model(input_tensor, output_layer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model=create_model(IMG_DIM, CHANNEL_SIZE, NUM_CLASSES)\n",
    "model.load_weights(\"../input/densenetmulti/dense-multi-0.8929.h5\")\n",
    "model.compile(optimizer=Adam(lr=0.00005), loss=keras.losses.mean_squared_error,  metrics=['accuracy'])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train set pipeline test\n",
    "Comment out before submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(INPUT_FOLDER + 'train.csv')\n",
    "# train_df['id_code'] = train_df['id_code'].apply(lambda x:  x + '.png')\n",
    "\n",
    "# block_size = 500\n",
    "# total = train_df.index.size\n",
    "\n",
    "# # have to do everything in blocks of images\n",
    "# for start in range(0, test_df.index.size, block_size):\n",
    "    \n",
    "#     gc.collect()\n",
    "    \n",
    "#     # get subset\n",
    "#     end = start + block_size\n",
    "#     end   = start + block_size\n",
    "#     if end > total:\n",
    "#         end = total\n",
    "    \n",
    "#     # process images\n",
    "#     img_list = np.empty((end-start, IMG_DIM, IMG_DIM, 3))\n",
    "#     for i, filename in enumerate(train_df[start:end].id_code):\n",
    "#         try:\n",
    "#             bgr = cv2.imread(INPUT_FOLDER + \"train_images/\" + filename)\n",
    "#             img_list[i,:,:,:] = processImageBgrToRgb(bgr)\n",
    "#         except:\n",
    "#             img_list[i,:,:,:] = 128.\n",
    "    \n",
    "#     # re scale to between 0 and 1\n",
    "#     img_list *= 1./255.\n",
    "    \n",
    "#     # make predictions\n",
    "#     predictions = model.predict(img_list, batch_size=BATCH_SIZE, verbose=1)\n",
    "#     predictions = predictions > 0.5\n",
    "#     y_pred = label_convert(predictions)\n",
    "#     y_val  = train_df['diagnosis'][start:end]\n",
    "    \n",
    "#     print(confusion_matrix(y_val, y_pred))\n",
    "    \n",
    "#     val_kappa = cohen_kappa_score(y_val, y_pred, weights='quadratic')\n",
    "\n",
    "#     print(f\"{start} - {end}: kappa: {val_kappa}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# figure=plt.figure(figsize=(22,20))\n",
    "# for target_class in (train_df['diagnosis'].unique()):\n",
    "#     sample = train_df[train_df.diagnosis == target_class].sample(2)\n",
    "#     for i, filename in enumerate(sample.id_code):\n",
    "        \n",
    "#         # original           \n",
    "#         bgr = cv2.imread(INPUT_FOLDER + \"train_images/\" + filename)\n",
    "#         rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "#         ax = figure.add_subplot(5,4, int(target_class)*4+2*i+1)\n",
    "#         plt.imshow(rgb)\n",
    "       \n",
    "#         # modified\n",
    "#         modified = processImageBgrToRgb(bgr)\n",
    "#         ax = figure.add_subplot(5,4, int(target_class)*4+2*i+2)\n",
    "#         plt.imshow(modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform predictions in slices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = test_df_extended\n",
    "block_size = 500\n",
    "total      = test_df.index.size\n",
    "y_pred_list = np.zeros(total, dtype=np.int)\n",
    "\n",
    "# have to do everything in blocks of images\n",
    "for start in range(0, total, block_size):\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    # get subset\n",
    "    end = start + block_size\n",
    "    if end > total:\n",
    "        end = total\n",
    "    \n",
    "    # process images\n",
    "    img_list = np.empty((end-start, IMG_DIM, IMG_DIM, 3))\n",
    "    for i, filename in enumerate(test_df[start:end].id_code):\n",
    "        try:\n",
    "            bgr = cv2.imread(TEST_IMAGES_DIR + filename)\n",
    "            img_list[i,:,:,:] = processImageBgrToRgb(bgr)\n",
    "        except:\n",
    "            img_list[i,:,:,:] = 128.\n",
    "    \n",
    "    # re scale to between 0 and 1\n",
    "    img_list *= 1./255.\n",
    "    \n",
    "    # make predictions\n",
    "    predictions = model.predict(img_list, batch_size=BATCH_SIZE, verbose=1)\n",
    "    predictions = predictions > 0.5\n",
    "    y_pred_list[start:end] = label_convert(predictions)\n",
    "\n",
    "    print(f\"{start} - {end} finished\")\n",
    "\n",
    "# save to csv\n",
    "test_df['diagnosis'] = y_pred_list\n",
    "test_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_amazonei_tensorflow_p36)",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

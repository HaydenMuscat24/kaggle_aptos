{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy  as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2 \n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "\n",
    "# import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.applications import DenseNet121\n",
    "from keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.activations import sigmoid\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Global constants\n",
    "IMG_DIM      = 256\n",
    "BATCH_SIZE   = 32\n",
    "CHANNEL_SIZE = 3\n",
    "NUM_CLASSES  = 5\n",
    "\n",
    "# data frame of current competition\n",
    "df_2019 = pd.read_csv(f\"../aptos2019/train.csv\") \n",
    "df_2019.id_code = df_2019.id_code.apply(lambda x: x + \".png\")\n",
    "df_2019.id_code = df_2019.id_code.apply(lambda x: \"modified_\" + x) \n",
    "train_2019, valid_2019 = train_test_split(df_2019, test_size=0.2, shuffle=False)\n",
    "\n",
    "# 2019 data frame \n",
    "df_2015 = pd.read_csv(f\"../aptos2015/trainLabels.csv\") \n",
    "df_2015.image   = df_2015.image.apply(lambda   x: x + \".jpeg\")\n",
    "df_2015[\"id_code\"]   = df_2015.image\n",
    "df_2015[\"diagnosis\"] = df_2015.level\n",
    "train_2015, valid_2015 = train_test_split(df_2015, test_size=0.2, shuffle=False)\n",
    "\n",
    "# valid_2019['diagnosis'].value_counts().plot(kind='bar')\n",
    "# plt.title('Samples Per Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "\n",
    "In this kernel, we are using multilabel data. Instead of predicting a single label, we will change our target to be a multilabel problem; i.e., if the target is a certain class, then it encompasses all the classes before it. E.g. encoding a class 4 retinopathy would usually be `[0, 0, 0, 1]`, but in our case we will predict `[1, 1, 1, 1]`. \n",
    "\n",
    "The idea is that if an eye has severe diabetic retinopathy, that also means that it has moderate and severe diabetic retinopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label_convert(y_val):\n",
    "    y_val = y_val.astype(int).sum(axis=1) - 1\n",
    "    #y_val= np.argmax(y_val, axis=1)\n",
    "    return y_val\n",
    "\n",
    "def get_train_valid_df(year=\"2019\", even_distrib=True):\n",
    "    \n",
    "    # shuffle data so each time different samples are dropped\n",
    "    if (year == \"2019\"):\n",
    "        train = train_2019.sample(frac=1)\n",
    "        valid = valid_2019.sample(frac=1)\n",
    "    elif (year == \"2015\"):\n",
    "        train = train_2015.sample(frac=1)\n",
    "        valid = valid_2015.sample(frac=1)\n",
    "    \n",
    "    # remap from classes to smoothed version of the classes\n",
    "    train[\"labels\"] = train.diagnosis.apply(lambda x: [i for i in range(x + 1)])\n",
    "    valid[\"labels\"] = valid.diagnosis.apply(lambda x: [i for i in range(x + 1)])\n",
    "\n",
    "    train.diagnosis = train.diagnosis.astype('str')\n",
    "    valid.diagnosis = valid.diagnosis.astype('str')\n",
    "\n",
    "    # drop classes \n",
    "    if even_distrib:\n",
    "        min_train = min(train['diagnosis'].value_counts())\n",
    "        min_valid = min(valid['diagnosis'].value_counts())\n",
    "\n",
    "        for diagnosis in range(5):\n",
    "            indexes_valid = valid[valid['diagnosis'] == str(diagnosis)].index\n",
    "            indexes_train = train[train['diagnosis'] == str(diagnosis)].index\n",
    "            \n",
    "            frac_drop_train = indexes_train.size * (1 - min_train/indexes_train.size)\n",
    "            frac_drop_valid = indexes_valid.size * (1 - min_valid/indexes_valid.size)\n",
    "            \n",
    "            train.drop(indexes_train[:int(frac_drop_train)], inplace=True)\n",
    "            valid.drop(indexes_valid[:int(frac_drop_valid)], inplace=True)\n",
    "\n",
    "    # shuffle it for even distribution\n",
    "    train = train.sample(frac=0.8)\n",
    "    valid = valid.sample(frac=0.8)\n",
    "    \n",
    "    return train, valid\n",
    "\n",
    "# plot example\n",
    "# _, df_to_plot = get_train_valid_df(year=\"2019\")\n",
    "# df_to_plot['diagnosis'].value_counts().plot(kind='bar')\n",
    "# plt.title('Samples Per Class')\n",
    "# print(df_to_plot.head(5))\n",
    "\n",
    "# df_to_plot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # display some data\n",
    "# df_example, _ = get_train_valid_df(year=\"2019\")\n",
    "\n",
    "# # Display some random images from Data Set with class categories.\n",
    "# figure=plt.figure(figsize=(22,20))\n",
    "# for target_class in (df_example['diagnosis'].unique()):\n",
    "#     for i, (idx, row ) in enumerate(df_example.loc[df_example.diagnosis == target_class]\n",
    "#                                     .sample(4)\n",
    "#                                     .iterrows()):\n",
    "#         # open the file\n",
    "#         imagefile = f\"../aptos2019/train_images/{row['id_code']}\" \n",
    "#         img = cv2.imread(imagefile)\n",
    "        \n",
    "#         # original version\n",
    "#         rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         ax = figure.add_subplot(5,4, int(target_class)*4+i+1)\n",
    "#         plt.imshow(rgb)\n",
    "#         ax.set_title(target_class)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data generators, which put their data into a random crop generator, which is then fed into\n",
    "# the network during training\n",
    "\n",
    "def dataGenerator(jitter=0.1):\n",
    "    datagen = image.ImageDataGenerator(rescale=1./255,\n",
    "                                       horizontal_flip=True and (jitter > 0.01), \n",
    "                                       vertical_flip=True and (jitter > 0.01),\n",
    "                                       rotation_range=int(800*jitter),\n",
    "                                       brightness_range=[1-jitter, 1+jitter],\n",
    "                                       channel_shift_range=int(30*jitter),\n",
    "                                       zoom_range=[(1-jitter), (1+jitter/2)],\n",
    "                                       fill_mode=\"reflect\",\n",
    "                                      )\n",
    "    return datagen\n",
    "\n",
    "def datagen_with_flow(datagen, dataframe, directory):\n",
    "    return datagen.flow_from_dataframe(dataframe=dataframe, directory=directory,\n",
    "                                       x_col=\"id_code\", \n",
    "                                       y_col='labels', \n",
    "                                       class_mode=\"categorical\", \n",
    "                                       batch_size=BATCH_SIZE,\n",
    "                                       target_size=(IMG_DIM, IMG_DIM),\n",
    "                                       shuffle=False,\n",
    "                                      )\n",
    "\n",
    "def generator(jitter=0.1, year=\"2019\", even_distrib=True):\n",
    "    \n",
    "    train, valid = get_train_valid_df(year=year, even_distrib=even_distrib) \n",
    "    datagen = dataGenerator(jitter)\n",
    "    \n",
    "    train_gen = datagen_with_flow(datagen, train, f\"../aptos{year}/train_images/\")\n",
    "    valid_gen = datagen_with_flow(datagen, valid, f\"../aptos{year}/train_images/\")\n",
    "    \n",
    "    return train_gen, valid_gen\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sample_gen, valid_sample_gen = generator(jitter=0.5)\n",
    "\n",
    "# # Display some data generation\n",
    "# figure=plt.figure(figsize=(22,20))\n",
    "# for batch in valid_sample_gen:\n",
    "#     for j in range(16):\n",
    "#         ax = figure.add_subplot(4,4, j+1)\n",
    "#         batch[0][j] = np.clip(batch[0][j], 0, 1)\n",
    "#         plt.imshow(batch[0][j])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(Callback):\n",
    "    def __init__(self, generator):\n",
    "        self.generator = generator\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_kappas = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        numBatches = 15\n",
    "        y_pred     = []\n",
    "        y_val      = []\n",
    "        for x, y in self.generator:\n",
    "            predictions = model.predict(x) \n",
    "            y_pred.extend(label_convert(predictions > 0.5))\n",
    "            y_val.extend(label_convert(y))\n",
    "            \n",
    "            numBatches -= 1\n",
    "            if numBatches <= 0:\n",
    "                break\n",
    "            \n",
    "        val_kappa = cohen_kappa_score(y_val, y_pred, weights='quadratic')\n",
    "        self.val_kappas.append(val_kappa)\n",
    "        \n",
    "        print(val_kappa)\n",
    "        print(confusion_matrix(y_val, y_pred))\n",
    "            \n",
    "        if val_kappa == max(self.val_kappas) and val_kappa > 0.84:\n",
    "            gc.collect()\n",
    "            print(\"Max of this run, saving model.\")\n",
    "            model.save(f\"dense-multi-second-{val_kappa:.4f}.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0815 03:41:13.220278 140365948131072 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0815 03:41:13.240477 140365948131072 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0815 03:41:13.245838 140365948131072 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0815 03:41:13.268116 140365948131072 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0815 03:41:13.269087 140365948131072 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0815 03:41:14.121256 140365948131072 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0815 03:41:14.195906 140365948131072 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0815 03:41:15.476514 140365948131072 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0815 03:41:36.367275 140365948131072 deprecation.py:506] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    #model.add(DenseNet121(weights='../DenseNet-BC-121-32-no-top.h5', \n",
    "    model.add(DenseNet121(weights=None, \n",
    "                          include_top=False, \n",
    "                          input_shape=(IMG_DIM,IMG_DIM,CHANNEL_SIZE)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.load_weights(\"../dense-multi-2015-run.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0815 03:41:48.224748 140365948131072 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0815 03:41:48.234390 140365948131072 deprecation.py:323] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ----------------------------------- 0.4 -----------------------------------\n",
      "           -   -   -   -   -   -   -   -    2019 False -   -   -   -   -   -   -   -   -\n",
      "Found 2343 validated image filenames belonging to 5 classes.\n",
      "Found 586 validated image filenames belonging to 5 classes.\n",
      "Epoch 1/4\n",
      "73/73 [==============================] - 137s 2s/step - loss: 0.1840 - acc: 0.9296 - val_loss: 0.1339 - val_acc: 0.9524\n",
      "0.8764564040047571\n",
      "[[238   3   3   0   0]\n",
      " [  3   2  28   1   0]\n",
      " [  1   4 100  12   1]\n",
      " [  0   1  11   9   3]\n",
      " [  1   1  13  12  11]]\n",
      "Max of this run, saving model.\n",
      "Epoch 2/4\n",
      "73/73 [==============================] - 85s 1s/step - loss: 0.1467 - acc: 0.9437 - val_loss: 0.1040 - val_acc: 0.9603\n",
      "0.8768949575314482\n",
      "[[240   3   1   0   0]\n",
      " [  3   3  22   0   2]\n",
      " [  1   6 101   7   2]\n",
      " [  0   0  15  11   2]\n",
      " [  1   0  18   5  15]]\n",
      "Max of this run, saving model.\n",
      "Epoch 3/4\n",
      "73/73 [==============================] - 83s 1s/step - loss: 0.1313 - acc: 0.9490 - val_loss: 0.1199 - val_acc: 0.9549\n",
      "0.9175421341290613\n",
      "[[249   9   0   0   0]\n",
      " [  5   8  22   0   0]\n",
      " [  0  10 101   5   1]\n",
      " [  0   0  13   6   3]\n",
      " [  0   0   8   5  13]]\n",
      "Max of this run, saving model.\n",
      "Epoch 4/4\n",
      "73/73 [==============================] - 83s 1s/step - loss: 0.1277 - acc: 0.9505 - val_loss: 0.1334 - val_acc: 0.9502\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "0.8912783541410234\n",
      "[[242   3   3   0   0]\n",
      " [  4   7  19   0   1]\n",
      " [  0   8 103   8   2]\n",
      " [  0   0   8   6   5]\n",
      " [  0   1  16   5  17]]\n",
      "           -   -   -   -   -   -   -   -    2019 True -   -   -   -   -   -   -   -   -\n",
      "Found 632 validated image filenames belonging to 5 classes.\n",
      "Found 140 validated image filenames belonging to 5 classes.\n",
      "Epoch 1/4\n",
      "19/19 [==============================] - 28s 1s/step - loss: 0.3688 - acc: 0.8516 - val_loss: 0.2101 - val_acc: 0.9078\n",
      "0.8261417556346382\n",
      "[[84  0  0  0  0]\n",
      " [ 8 26 40  1  0]\n",
      " [ 4  8 68  4  0]\n",
      " [ 0  0 52 25 16]\n",
      " [ 0  0 26 16 42]]\n",
      "Epoch 2/4\n",
      "19/19 [==============================] - 24s 1s/step - loss: 0.3182 - acc: 0.8711 - val_loss: 0.2180 - val_acc: 0.9000\n",
      "0.8198181271606794\n",
      "[[84  0  0  0  0]\n",
      " [ 7 33 33  2  0]\n",
      " [ 2 12 65  5  0]\n",
      " [ 0  0 52 29 12]\n",
      " [ 0  2 25 19 38]]\n",
      "Epoch 3/4\n",
      "19/19 [==============================] - 21s 1s/step - loss: 0.3024 - acc: 0.8796 - val_loss: 0.2154 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.9999999949504855e-07.\n",
      "0.8111535052221837\n",
      "[[84  0  0  0  0]\n",
      " [ 3 36 35  1  0]\n",
      " [ 1 10 69  4  0]\n",
      " [ 0  1 48 30 14]\n",
      " [ 0  1 31 21 31]]\n",
      "Epoch 4/4\n",
      "19/19 [==============================] - 21s 1s/step - loss: 0.2833 - acc: 0.8809 - val_loss: 0.2177 - val_acc: 0.9000\n",
      "0.8163925887342808\n",
      "[[84  0  0  0  0]\n",
      " [ 6 38 31  0  0]\n",
      " [ 4 16 60  4  0]\n",
      " [ 1  1 47 30 14]\n",
      " [ 0  1 26 22 35]]\n",
      "           ----------------------------------- 0.2 -----------------------------------\n",
      "           -   -   -   -   -   -   -   -    2019 False -   -   -   -   -   -   -   -   -\n",
      "Found 2343 validated image filenames belonging to 5 classes.\n",
      "Found 586 validated image filenames belonging to 5 classes.\n",
      "Epoch 1/4\n",
      "73/73 [==============================] - 139s 2s/step - loss: 0.1180 - acc: 0.9535 - val_loss: 0.1166 - val_acc: 0.9528\n",
      "0.8858594069863347\n",
      "[[227   5   0   0   0]\n",
      " [  5  14  23   1   0]\n",
      " [  1  10 104   4   3]\n",
      " [  0   0  11   4   4]\n",
      " [  0   2  15   8  17]]\n",
      "Max of this run, saving model.\n",
      "Epoch 2/4\n",
      "73/73 [==============================] - 84s 1s/step - loss: 0.1100 - acc: 0.9561 - val_loss: 0.1073 - val_acc: 0.9560\n",
      "0.899620404524134\n",
      "[[223   5   0   0   0]\n",
      " [  2  18  22   1   0]\n",
      " [  0  14 101   8   2]\n",
      " [  0   0  12   6   3]\n",
      " [  0   0  15   9  17]]\n",
      "Max of this run, saving model.\n",
      "Epoch 3/4\n",
      "73/73 [==============================] - 84s 1s/step - loss: 0.1067 - acc: 0.9568 - val_loss: 0.1239 - val_acc: 0.9509\n",
      "0.8920769960522692\n",
      "[[243   5   0   0   0]\n",
      " [  5  18  22   1   0]\n",
      " [  1  13  89   3   2]\n",
      " [  0   0   8   7   1]\n",
      " [  1   0  15   5  19]]\n",
      "Epoch 4/4\n",
      "73/73 [==============================] - 83s 1s/step - loss: 0.1076 - acc: 0.9578 - val_loss: 0.1302 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "0.8968878999061694\n",
      "[[228   3   1   0   0]\n",
      " [  6  15  17   0   0]\n",
      " [  0   8 110   3   2]\n",
      " [  0   0  10   6   4]\n",
      " [  0   1  19   7  18]]\n",
      "           -   -   -   -   -   -   -   -    2019 True -   -   -   -   -   -   -   -   -\n",
      "Found 632 validated image filenames belonging to 5 classes.\n",
      "Found 140 validated image filenames belonging to 5 classes.\n",
      "Epoch 1/4\n",
      "19/19 [==============================] - 28s 1s/step - loss: 0.3354 - acc: 0.8704 - val_loss: 0.2036 - val_acc: 0.9062\n",
      "0.826680474486914\n",
      "[[78  0  0  0  0]\n",
      " [12 42 33  0  0]\n",
      " [ 0  6 75  0  0]\n",
      " [ 0  0 41 32 14]\n",
      " [ 0  2 32 11 42]]\n",
      "Epoch 2/4\n",
      "19/19 [==============================] - 21s 1s/step - loss: 0.3254 - acc: 0.8718 - val_loss: 0.2120 - val_acc: 0.9111\n",
      "0.8015947998941839\n",
      "[[78  0  0  0  0]\n",
      " [13 41 33  0  0]\n",
      " [ 0 10 71  0  0]\n",
      " [ 0  0 45 29 13]\n",
      " [ 0  6 30 12 39]]\n",
      "Epoch 3/4\n",
      "19/19 [==============================] - 21s 1s/step - loss: 0.2889 - acc: 0.8816 - val_loss: 0.2553 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "0.8083118556701031\n",
      "[[78  0  0  0  0]\n",
      " [13 44 30  0  0]\n",
      " [ 0 11 70  0  0]\n",
      " [ 0  0 50 25 12]\n",
      " [ 0  5 28 16 38]]\n",
      "Epoch 4/4\n",
      "19/19 [==============================] - 21s 1s/step - loss: 0.2638 - acc: 0.8910 - val_loss: 0.2118 - val_acc: 0.9056\n",
      "0.7985208092700921\n",
      "[[78  0  0  0  0]\n",
      " [17 39 31  0  0]\n",
      " [ 1  9 71  0  0]\n",
      " [ 0  0 46 27 14]\n",
      " [ 0  8 25 16 38]]\n",
      "           ----------------------------------- 0.05 -----------------------------------\n",
      "           -   -   -   -   -   -   -   -    2019 False -   -   -   -   -   -   -   -   -\n",
      "Found 2343 validated image filenames belonging to 5 classes.\n",
      "Found 586 validated image filenames belonging to 5 classes.\n",
      "Epoch 1/4\n",
      "73/73 [==============================] - 144s 2s/step - loss: 0.1030 - acc: 0.9595 - val_loss: 0.1075 - val_acc: 0.9569\n",
      "0.8959874474728193\n",
      "[[246   1   0   0   0]\n",
      " [  2  18  22   0   0]\n",
      " [  1  18  90   2   1]\n",
      " [  0   1  11   5   4]\n",
      " [  0   0  16   7  13]]\n",
      "Max of this run, saving model.\n",
      "Epoch 2/4\n",
      "73/73 [==============================] - 84s 1s/step - loss: 0.0990 - acc: 0.9605 - val_loss: 0.1113 - val_acc: 0.9542\n",
      "0.9038169771049948\n",
      "[[244   1   0   0   0]\n",
      " [  3  16  14   0   0]\n",
      " [  2  13  88   4   1]\n",
      " [  0   0  17   9   2]\n",
      " [  0   2  13  11  18]]\n",
      "Max of this run, saving model.\n",
      "Epoch 3/4\n",
      "73/73 [==============================] - 84s 1s/step - loss: 0.0990 - acc: 0.9619 - val_loss: 0.1014 - val_acc: 0.9588\n",
      "0.8931220328603746\n",
      "[[245   2   0   0   0]\n",
      " [  3  16  20   1   0]\n",
      " [  1  14  91   0   2]\n",
      " [  0   0  12   5   3]\n",
      " [  0   2  15   9  17]]\n",
      "Epoch 4/4\n",
      "73/73 [==============================] - 84s 1s/step - loss: 0.0957 - acc: 0.9631 - val_loss: 0.1004 - val_acc: 0.9581\n",
      "0.907061416954992\n",
      "[[246   3   0   0   0]\n",
      " [  3  17  18   0   0]\n",
      " [  1  10  85   5   1]\n",
      " [  0   0  18   8   6]\n",
      " [  0   2  11   6  18]]\n",
      "Max of this run, saving model.\n",
      "           -   -   -   -   -   -   -   -    2019 True -   -   -   -   -   -   -   -   -\n",
      "Found 632 validated image filenames belonging to 5 classes.\n",
      "Found 140 validated image filenames belonging to 5 classes.\n",
      "Epoch 1/4\n",
      "19/19 [==============================] - 28s 1s/step - loss: 0.2987 - acc: 0.8776 - val_loss: 0.2369 - val_acc: 0.8984\n",
      "0.7891857732488101\n",
      "[[75  0  0  0  0]\n",
      " [ 7 38 36  0  0]\n",
      " [ 2 27 60  1  0]\n",
      " [ 0  1 60 18 14]\n",
      " [ 0  3 26 17 35]]\n",
      "Epoch 2/4\n",
      "19/19 [==============================] - 21s 1s/step - loss: 0.2498 - acc: 0.8982 - val_loss: 0.2176 - val_acc: 0.9000\n",
      "0.7866189427312775\n",
      "[[75  0  0  0  0]\n",
      " [ 9 37 35  0  0]\n",
      " [ 4 30 55  1  0]\n",
      " [ 0  2 50 30 11]\n",
      " [ 0  3 25 23 30]]\n",
      "Epoch 3/4\n",
      "19/19 [==============================] - 21s 1s/step - loss: 0.2179 - acc: 0.9098 - val_loss: 0.2419 - val_acc: 0.9037\n",
      "0.7910181868013547\n",
      "[[75  0  0  0  0]\n",
      " [ 9 39 33  0  0]\n",
      " [ 5 27 57  1  0]\n",
      " [ 0  0 53 26 14]\n",
      " [ 0  3 24 25 29]]\n",
      "Epoch 4/4\n",
      "19/19 [==============================] - 21s 1s/step - loss: 0.2057 - acc: 0.9151 - val_loss: 0.2689 - val_acc: 0.8907\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-07.\n",
      "0.7911924012873852\n",
      "[[75  0  0  0  0]\n",
      " [ 7 41 32  1  0]\n",
      " [ 3 32 54  1  0]\n",
      " [ 0  2 44 34 13]\n",
      " [ 0  3 25 24 29]]\n"
     ]
    }
   ],
   "source": [
    " for jitter in [0.4, 0.2, 0.05]:\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=0.00005*jitter), loss='binary_crossentropy',  metrics=['accuracy'])\n",
    "    \n",
    "    print(\"           -----------------------------------\", \n",
    "          jitter, \"-----------------------------------\")\n",
    "    \n",
    "    for even_distrib in [False, True]:\n",
    "        \n",
    "        for year in [\"2019\"]:\n",
    "\n",
    "            print(\"           -   -   -   -   -   -   -   -   \", year, \n",
    "                  even_distrib, \"-   -   -   -   -   -   -   -   -\")\n",
    "            \n",
    "            # these need to be global for the kappa callback\n",
    "            train_generator, valid_generator = generator(jitter=jitter, year=year, even_distrib=even_distrib)\n",
    "\n",
    "            # Call backs during training            \n",
    "            kappa_callbacks = Metrics(valid_generator)\n",
    "            reduce_lr  = ReduceLROnPlateau(monitor='val_loss', min_delta=0.0004, patience=2, \n",
    "                                           min_lr=1e-8, mode='auto', verbose=1)\n",
    "\n",
    "            # train the model for 12 epochs\n",
    "            history = model.fit_generator(generator=train_generator,\n",
    "                                          steps_per_epoch=train_generator.n  // train_generator.batch_size,\n",
    "                                          validation_data=valid_generator,\n",
    "                                          validation_steps=valid_generator.n // valid_generator.batch_size,\n",
    "                                          epochs=4, workers=4, verbose=1,\n",
    "                                          callbacks=[reduce_lr, kappa_callbacks],\n",
    "                                         )\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"dense-multi-2019-run.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the average of 5 randomised jitters to a non-jittered val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 586 validated image filenames belonging to 5 classes.\n",
      "19/19 [==============================] - 14s 745ms/step\n",
      "Found 586 validated image filenames belonging to 5 classes.\n",
      "19/19 [==============================] - 15s 812ms/step\n",
      "Found 586 validated image filenames belonging to 5 classes.\n",
      "19/19 [==============================] - 14s 760ms/step\n",
      "Found 586 validated image filenames belonging to 5 classes.\n",
      "19/19 [==============================] - 15s 775ms/step\n",
      "Found 586 validated image filenames belonging to 5 classes.\n",
      "19/19 [==============================] - 15s 786ms/step\n",
      "Found 586 validated image filenames belonging to 5 classes.\n",
      "19/19 [==============================] - 15s 792ms/step\n",
      "Found 586 validated image filenames belonging to 5 classes.\n",
      "19/19 [==============================] - 15s 775ms/step\n",
      "With jitter:  0.8987738928725032\n",
      "[[314   4   0   0   0]\n",
      " [  6  20  14   0   0]\n",
      " [  1  25 110   4   1]\n",
      " [  0   1  14  13   4]\n",
      " [  1   2  17  11  24]]\n",
      "Found 586 validated image filenames belonging to 5 classes.\n",
      "19/19 [==============================] - 7s 378ms/step\n"
     ]
    }
   ],
   "source": [
    "def compare_prediction_process(year=\"2019\"):\n",
    "\n",
    "    _, valid_df = get_train_valid_df(year=year, even_distrib=False)\n",
    "    \n",
    "    y_val  = valid_df.diagnosis.astype(int)\n",
    "\n",
    "    # with jitter\n",
    "    num = 7\n",
    "    prediction_lists = np.zeros((valid_df.index.size, num, 5))\n",
    "    for i in range(num):\n",
    "        datagen = datagen_with_flow(dataGenerator(0.03), valid_df, f\"../aptos{year}/train_images/\")\n",
    "        prediction_lists[:, i] = model.predict_generator(generator=datagen, steps=len(datagen), workers=4, verbose=1)\n",
    "\n",
    "    predictions = np.median(prediction_lists, axis=1)\n",
    "    y_pred = label_convert(predictions > 0.5)\n",
    "    \n",
    "    print(\"With jitter: \", cohen_kappa_score(y_val, y_pred, weights='quadratic'))\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "          \n",
    "    # no jitter\n",
    "    datagen = datagen_with_flow(dataGenerator(0), valid_df, f\"../aptos{year}/train_images/\")\n",
    "    predictions = model.predict_generator(generator=datagen, steps=len(datagen), workers=4, verbose=1)\n",
    "    y_pred = label_convert(predictions > 0.5)\n",
    "    \n",
    "    print(\"With no jitter: \", cohen_kappa_score(y_val, y_pred, weights='quadratic'))\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "            \n",
    "    \n",
    "compare_prediction_process(\"2019\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
